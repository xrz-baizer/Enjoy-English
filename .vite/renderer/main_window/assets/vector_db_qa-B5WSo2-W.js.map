{"version":3,"file":"vector_db_qa-B5WSo2-W.js","sources":["../../../../node_modules/@langchain/core/dist/example_selectors/conditional.js","../../../../node_modules/langchain/dist/chains/question_answering/stuff_prompts.js","../../../../node_modules/langchain/dist/chains/question_answering/load.js","../../../../node_modules/langchain/dist/chains/vector_db_qa.js"],"sourcesContent":["/**\n * Abstract class that defines the interface for selecting a prompt for a\n * given language model.\n */\nexport class BasePromptSelector {\n    /**\n     * Asynchronous version of `getPrompt` that also accepts an options object\n     * for partial variables.\n     * @param llm The language model for which to get a prompt.\n     * @param options Optional object for partial variables.\n     * @returns A Promise that resolves to a prompt template.\n     */\n    async getPromptAsync(llm, options) {\n        const prompt = this.getPrompt(llm);\n        return prompt.partial(options?.partialVariables ?? {});\n    }\n}\n/**\n * Concrete implementation of `BasePromptSelector` that selects a prompt\n * based on a set of conditions. It has a default prompt that it returns\n * if none of the conditions are met.\n */\nexport class ConditionalPromptSelector extends BasePromptSelector {\n    constructor(default_prompt, conditionals = []) {\n        super();\n        Object.defineProperty(this, \"defaultPrompt\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"conditionals\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.defaultPrompt = default_prompt;\n        this.conditionals = conditionals;\n    }\n    /**\n     * Method that selects a prompt based on a set of conditions. If none of\n     * the conditions are met, it returns the default prompt.\n     * @param llm The language model for which to get a prompt.\n     * @returns A prompt template.\n     */\n    getPrompt(llm) {\n        for (const [condition, prompt] of this.conditionals) {\n            if (condition(llm)) {\n                return prompt;\n            }\n        }\n        return this.defaultPrompt;\n    }\n}\n/**\n * Type guard function that checks if a given language model is of type\n * `BaseLLM`.\n */\nexport function isLLM(llm) {\n    return llm._modelType() === \"base_llm\";\n}\n/**\n * Type guard function that checks if a given language model is of type\n * `BaseChatModel`.\n */\nexport function isChatModel(llm) {\n    return llm._modelType() === \"base_chat_model\";\n}\n","/* eslint-disable spaced-comment */\nimport { ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, PromptTemplate, } from \"@langchain/core/prompts\";\nimport { ConditionalPromptSelector, isChatModel, } from \"@langchain/core/example_selectors\";\nexport const DEFAULT_QA_PROMPT = /*#__PURE__*/ new PromptTemplate({\n    template: \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\",\n    inputVariables: [\"context\", \"question\"],\n});\nconst system_template = `Use the following pieces of context to answer the users question. \nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\n----------------\n{context}`;\nconst messages = [\n    /*#__PURE__*/ SystemMessagePromptTemplate.fromTemplate(system_template),\n    /*#__PURE__*/ HumanMessagePromptTemplate.fromTemplate(\"{question}\"),\n];\nconst CHAT_PROMPT = /*#__PURE__*/ ChatPromptTemplate.fromMessages(messages);\nexport const QA_PROMPT_SELECTOR = /*#__PURE__*/ new ConditionalPromptSelector(DEFAULT_QA_PROMPT, [[isChatModel, CHAT_PROMPT]]);\n","import { LLMChain } from \"../llm_chain.js\";\nimport { StuffDocumentsChain, MapReduceDocumentsChain, RefineDocumentsChain, } from \"../combine_docs_chain.js\";\nimport { QA_PROMPT_SELECTOR } from \"./stuff_prompts.js\";\nimport { COMBINE_PROMPT_SELECTOR, COMBINE_QA_PROMPT_SELECTOR, } from \"./map_reduce_prompts.js\";\nimport { QUESTION_PROMPT_SELECTOR, REFINE_PROMPT_SELECTOR, } from \"./refine_prompts.js\";\nexport const loadQAChain = (llm, params = { type: \"stuff\" }) => {\n    const { type } = params;\n    if (type === \"stuff\") {\n        return loadQAStuffChain(llm, params);\n    }\n    if (type === \"map_reduce\") {\n        return loadQAMapReduceChain(llm, params);\n    }\n    if (type === \"refine\") {\n        return loadQARefineChain(llm, params);\n    }\n    throw new Error(`Invalid _type: ${type}`);\n};\n/**\n * Loads a StuffQAChain based on the provided parameters. It takes an LLM\n * instance and StuffQAChainParams as parameters.\n * @param llm An instance of BaseLanguageModel.\n * @param params Parameters for creating a StuffQAChain.\n * @returns A StuffQAChain instance.\n */\nexport function loadQAStuffChain(llm, params = {}) {\n    const { prompt = QA_PROMPT_SELECTOR.getPrompt(llm), verbose } = params;\n    const llmChain = new LLMChain({ prompt, llm, verbose });\n    const chain = new StuffDocumentsChain({ llmChain, verbose });\n    return chain;\n}\n/**\n * Loads a MapReduceQAChain based on the provided parameters. It takes an\n * LLM instance and MapReduceQAChainParams as parameters.\n * @param llm An instance of BaseLanguageModel.\n * @param params Parameters for creating a MapReduceQAChain.\n * @returns A MapReduceQAChain instance.\n */\nexport function loadQAMapReduceChain(llm, params = {}) {\n    const { combineMapPrompt = COMBINE_QA_PROMPT_SELECTOR.getPrompt(llm), combinePrompt = COMBINE_PROMPT_SELECTOR.getPrompt(llm), verbose, combineLLM, returnIntermediateSteps, } = params;\n    const llmChain = new LLMChain({ prompt: combineMapPrompt, llm, verbose });\n    const combineLLMChain = new LLMChain({\n        prompt: combinePrompt,\n        llm: combineLLM ?? llm,\n        verbose,\n    });\n    const combineDocumentChain = new StuffDocumentsChain({\n        llmChain: combineLLMChain,\n        documentVariableName: \"summaries\",\n        verbose,\n    });\n    const chain = new MapReduceDocumentsChain({\n        llmChain,\n        combineDocumentChain,\n        returnIntermediateSteps,\n        verbose,\n    });\n    return chain;\n}\n/**\n * Loads a RefineQAChain based on the provided parameters. It takes an LLM\n * instance and RefineQAChainParams as parameters.\n * @param llm An instance of BaseLanguageModel.\n * @param params Parameters for creating a RefineQAChain.\n * @returns A RefineQAChain instance.\n */\nexport function loadQARefineChain(llm, params = {}) {\n    const { questionPrompt = QUESTION_PROMPT_SELECTOR.getPrompt(llm), refinePrompt = REFINE_PROMPT_SELECTOR.getPrompt(llm), refineLLM, verbose, } = params;\n    const llmChain = new LLMChain({ prompt: questionPrompt, llm, verbose });\n    const refineLLMChain = new LLMChain({\n        prompt: refinePrompt,\n        llm: refineLLM ?? llm,\n        verbose,\n    });\n    const chain = new RefineDocumentsChain({\n        llmChain,\n        refineLLMChain,\n        verbose,\n    });\n    return chain;\n}\n","import { BaseChain } from \"./base.js\";\nimport { loadQAStuffChain } from \"./question_answering/load.js\";\n/**\n * Class that represents a VectorDBQAChain. It extends the `BaseChain`\n * class and implements the `VectorDBQAChainInput` interface. It performs\n * a similarity search using a vector store and combines the search\n * results using a specified combine documents chain.\n *\n * @deprecated\n * Switch to {@link https://js.langchain.com/docs/modules/chains/ | createRetrievalChain}\n * Will be removed in 0.2.0\n */\nexport class VectorDBQAChain extends BaseChain {\n    static lc_name() {\n        return \"VectorDBQAChain\";\n    }\n    get inputKeys() {\n        return [this.inputKey];\n    }\n    get outputKeys() {\n        return this.combineDocumentsChain.outputKeys.concat(this.returnSourceDocuments ? [\"sourceDocuments\"] : []);\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"k\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 4\n        });\n        Object.defineProperty(this, \"inputKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"query\"\n        });\n        Object.defineProperty(this, \"vectorstore\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"combineDocumentsChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"returnSourceDocuments\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        this.vectorstore = fields.vectorstore;\n        this.combineDocumentsChain = fields.combineDocumentsChain;\n        this.inputKey = fields.inputKey ?? this.inputKey;\n        this.k = fields.k ?? this.k;\n        this.returnSourceDocuments =\n            fields.returnSourceDocuments ?? this.returnSourceDocuments;\n    }\n    /** @ignore */\n    async _call(values, runManager) {\n        if (!(this.inputKey in values)) {\n            throw new Error(`Question key ${this.inputKey} not found.`);\n        }\n        const question = values[this.inputKey];\n        const docs = await this.vectorstore.similaritySearch(question, this.k, values.filter, runManager?.getChild(\"vectorstore\"));\n        const inputs = { question, input_documents: docs };\n        const result = await this.combineDocumentsChain.call(inputs, runManager?.getChild(\"combine_documents\"));\n        if (this.returnSourceDocuments) {\n            return {\n                ...result,\n                sourceDocuments: docs,\n            };\n        }\n        return result;\n    }\n    _chainType() {\n        return \"vector_db_qa\";\n    }\n    static async deserialize(data, values) {\n        if (!(\"vectorstore\" in values)) {\n            throw new Error(`Need to pass in a vectorstore to deserialize VectorDBQAChain`);\n        }\n        const { vectorstore } = values;\n        if (!data.combine_documents_chain) {\n            throw new Error(`VectorDBQAChain must have combine_documents_chain in serialized data`);\n        }\n        return new VectorDBQAChain({\n            combineDocumentsChain: await BaseChain.deserialize(data.combine_documents_chain),\n            k: data.k,\n            vectorstore,\n        });\n    }\n    serialize() {\n        return {\n            _type: this._chainType(),\n            combine_documents_chain: this.combineDocumentsChain.serialize(),\n            k: this.k,\n        };\n    }\n    /**\n     * Static method that creates a VectorDBQAChain instance from a\n     * BaseLanguageModel and a vector store. It also accepts optional options\n     * to customize the chain.\n     * @param llm The BaseLanguageModel instance.\n     * @param vectorstore The vector store used for similarity search.\n     * @param options Optional options to customize the chain.\n     * @returns A new instance of VectorDBQAChain.\n     */\n    static fromLLM(llm, vectorstore, options) {\n        const qaChain = loadQAStuffChain(llm);\n        return new this({\n            vectorstore,\n            combineDocumentsChain: qaChain,\n            ...options,\n        });\n    }\n}\n"],"names":["BasePromptSelector","llm","options","ConditionalPromptSelector","default_prompt","conditionals","condition","prompt","isChatModel","DEFAULT_QA_PROMPT","PromptTemplate","system_template","messages","SystemMessagePromptTemplate","HumanMessagePromptTemplate","CHAT_PROMPT","ChatPromptTemplate","QA_PROMPT_SELECTOR","loadQAStuffChain","params","verbose","llmChain","LLMChain","StuffDocumentsChain","VectorDBQAChain","BaseChain","fields","values","runManager","question","docs","inputs","result","data","vectorstore","qaChain"],"mappings":"kJAIO,MAAMA,CAAmB,CAQ5B,MAAM,eAAeC,EAAKC,EAAS,CAE/B,OADe,KAAK,UAAUD,CAAG,EACnB,QAAQC,GAAS,kBAAoB,CAAA,CAAE,CACzD,CACJ,CAMO,MAAMC,UAAkCH,CAAmB,CAC9D,YAAYI,EAAgBC,EAAe,GAAI,CAC3C,MAAK,EACL,OAAO,eAAe,KAAM,gBAAiB,CACzC,WAAY,GACZ,aAAc,GACd,SAAU,GACV,MAAO,MACnB,CAAS,EACD,OAAO,eAAe,KAAM,eAAgB,CACxC,WAAY,GACZ,aAAc,GACd,SAAU,GACV,MAAO,MACnB,CAAS,EACD,KAAK,cAAgBD,EACrB,KAAK,aAAeC,CACxB,CAOA,UAAUJ,EAAK,CACX,SAAW,CAACK,EAAWC,CAAM,IAAK,KAAK,aACnC,GAAID,EAAUL,CAAG,EACb,OAAOM,EAGf,OAAO,KAAK,aAChB,CACJ,CAYO,SAASC,EAAYP,EAAK,CAC7B,OAAOA,EAAI,WAAU,IAAO,iBAChC,CCjEO,MAAMQ,EAAkC,IAAIC,EAAe,CAC9D,SAAU;AAAA;AAAA;AAAA;AAAA;AAAA,iBACV,eAAgB,CAAC,UAAW,UAAU,CAC1C,CAAC,EACKC,EAAkB;AAAA;AAAA;AAAA,WAIlBC,EAAW,CACCC,EAA4B,aAAaF,CAAe,EACxDG,EAA2B,aAAa,YAAY,CACtE,EACMC,EAA4BC,EAAmB,aAAaJ,CAAQ,EAC7DK,EAAmC,IAAId,EAA0BM,EAAmB,CAAC,CAACD,EAAaO,CAAW,CAAC,CAAC,ECStH,SAASG,EAAiBjB,EAAKkB,EAAS,GAAI,CAC/C,KAAM,CAAE,OAAAZ,EAASU,EAAmB,UAAUhB,CAAG,EAAG,QAAAmB,CAAO,EAAKD,EAC1DE,EAAW,IAAIC,EAAS,CAAE,OAAAf,EAAQ,IAAAN,EAAK,QAAAmB,EAAS,EAEtD,OADc,IAAIG,EAAoB,CAAE,SAAAF,EAAU,QAAAD,CAAO,CAAE,CAE/D,CClBO,MAAMI,UAAwBC,CAAU,CAC3C,OAAO,SAAU,CACb,MAAO,iBACX,CACA,IAAI,WAAY,CACZ,MAAO,CAAC,KAAK,QAAQ,CACzB,CACA,IAAI,YAAa,CACb,OAAO,KAAK,sBAAsB,WAAW,OAAO,KAAK,sBAAwB,CAAC,iBAAiB,EAAI,EAAE,CAC7G,CACA,YAAYC,EAAQ,CAChB,MAAMA,CAAM,EACZ,OAAO,eAAe,KAAM,IAAK,CAC7B,WAAY,GACZ,aAAc,GACd,SAAU,GACV,MAAO,CACnB,CAAS,EACD,OAAO,eAAe,KAAM,WAAY,CACpC,WAAY,GACZ,aAAc,GACd,SAAU,GACV,MAAO,OACnB,CAAS,EACD,OAAO,eAAe,KAAM,cAAe,CACvC,WAAY,GACZ,aAAc,GACd,SAAU,GACV,MAAO,MACnB,CAAS,EACD,OAAO,eAAe,KAAM,wBAAyB,CACjD,WAAY,GACZ,aAAc,GACd,SAAU,GACV,MAAO,MACnB,CAAS,EACD,OAAO,eAAe,KAAM,wBAAyB,CACjD,WAAY,GACZ,aAAc,GACd,SAAU,GACV,MAAO,EACnB,CAAS,EACD,KAAK,YAAcA,EAAO,YAC1B,KAAK,sBAAwBA,EAAO,sBACpC,KAAK,SAAWA,EAAO,UAAY,KAAK,SACxC,KAAK,EAAIA,EAAO,GAAK,KAAK,EAC1B,KAAK,sBACDA,EAAO,uBAAyB,KAAK,qBAC7C,CAEA,MAAM,MAAMC,EAAQC,EAAY,CAC5B,GAAI,EAAE,KAAK,YAAYD,GACnB,MAAM,IAAI,MAAM,gBAAgB,KAAK,QAAQ,aAAa,EAE9D,MAAME,EAAWF,EAAO,KAAK,QAAQ,EAC/BG,EAAO,MAAM,KAAK,YAAY,iBAAiBD,EAAU,KAAK,EAAGF,EAAO,OAAQC,GAAY,SAAS,aAAa,CAAC,EACnHG,EAAS,CAAE,SAAAF,EAAU,gBAAiBC,CAAI,EAC1CE,EAAS,MAAM,KAAK,sBAAsB,KAAKD,EAAQH,GAAY,SAAS,mBAAmB,CAAC,EACtG,OAAI,KAAK,sBACE,CACH,GAAGI,EACH,gBAAiBF,CACjC,EAEeE,CACX,CACA,YAAa,CACT,MAAO,cACX,CACA,aAAa,YAAYC,EAAMN,EAAQ,CACnC,GAAI,EAAE,gBAAiBA,GACnB,MAAM,IAAI,MAAM,8DAA8D,EAElF,KAAM,CAAE,YAAAO,CAAW,EAAKP,EACxB,GAAI,CAACM,EAAK,wBACN,MAAM,IAAI,MAAM,sEAAsE,EAE1F,OAAO,IAAIT,EAAgB,CACvB,sBAAuB,MAAMC,EAAU,YAAYQ,EAAK,uBAAuB,EAC/E,EAAGA,EAAK,EACR,YAAAC,CACZ,CAAS,CACL,CACA,WAAY,CACR,MAAO,CACH,MAAO,KAAK,WAAU,EACtB,wBAAyB,KAAK,sBAAsB,UAAS,EAC7D,EAAG,KAAK,CACpB,CACI,CAUA,OAAO,QAAQjC,EAAKiC,EAAahC,EAAS,CACtC,MAAMiC,EAAUjB,EAAiBjB,CAAG,EACpC,OAAO,IAAI,KAAK,CACZ,YAAAiC,EACA,sBAAuBC,EACvB,GAAGjC,CACf,CAAS,CACL,CACJ","x_google_ignoreList":[0,1,2,3]}